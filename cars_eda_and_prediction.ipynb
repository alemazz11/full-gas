{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14336798,"sourceType":"datasetVersion","datasetId":9153571}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/alemazz11/used-cars-analysis-and-price-prediction?scriptVersionId=294743877\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', None)\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:03:57.165925Z","iopub.execute_input":"2026-01-29T11:03:57.166252Z","iopub.status.idle":"2026-01-29T11:03:57.526748Z","shell.execute_reply.started":"2026-01-29T11:03:57.166223Z","shell.execute_reply":"2026-01-29T11:03:57.525805Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. Data Cleaning\n","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/cars-europe/fullGas.csv\")\ndf.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:03:57.528269Z","iopub.execute_input":"2026-01-29T11:03:57.528702Z","iopub.status.idle":"2026-01-29T11:03:57.92844Z","shell.execute_reply.started":"2026-01-29T11:03:57.528672Z","shell.execute_reply":"2026-01-29T11:03:57.92762Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:03:57.929548Z","iopub.execute_input":"2026-01-29T11:03:57.930085Z","iopub.status.idle":"2026-01-29T11:03:57.978875Z","shell.execute_reply.started":"2026-01-29T11:03:57.930059Z","shell.execute_reply":"2026-01-29T11:03:57.977737Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Checking for duplicates","metadata":{}},{"cell_type":"code","source":"df.duplicated().sum() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:03:57.981249Z","iopub.execute_input":"2026-01-29T11:03:57.981582Z","iopub.status.idle":"2026-01-29T11:03:58.063436Z","shell.execute_reply.started":"2026-01-29T11:03:57.981548Z","shell.execute_reply":"2026-01-29T11:03:58.062516Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.1 Handling missing values","metadata":{}},{"cell_type":"markdown","source":"Let's start by removing the columns\n* Fuel_Consumption_l  : Almost 70% of data missing\n* Gears               : Not so important for analysis and almost half of data missing\n* Previous_Owners     : Almost 50% of data missing","metadata":{}},{"cell_type":"code","source":"df.drop(columns = [\"Fuel_Consumption_l\", 'Gears', \"Previous_Owners\"], inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:03:58.064766Z","iopub.execute_input":"2026-01-29T11:03:58.065009Z","iopub.status.idle":"2026-01-29T11:03:58.082258Z","shell.execute_reply.started":"2026-01-29T11:03:58.064988Z","shell.execute_reply":"2026-01-29T11:03:58.080923Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:03:58.08422Z","iopub.execute_input":"2026-01-29T11:03:58.084592Z","iopub.status.idle":"2026-01-29T11:03:58.125289Z","shell.execute_reply.started":"2026-01-29T11:03:58.084561Z","shell.execute_reply":"2026-01-29T11:03:58.124165Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[df['Model'].isna()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:03:58.126524Z","iopub.execute_input":"2026-01-29T11:03:58.127419Z","iopub.status.idle":"2026-01-29T11:03:58.159664Z","shell.execute_reply.started":"2026-01-29T11:03:58.127362Z","shell.execute_reply":"2026-01-29T11:03:58.158704Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Since we want to look at Model in our Data Exploration and there are many null values in other columns, i'll remove those 200 rows.","metadata":{}},{"cell_type":"code","source":"df.dropna(subset=['Model'], inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:03:58.161014Z","iopub.execute_input":"2026-01-29T11:03:58.161471Z","iopub.status.idle":"2026-01-29T11:03:58.188798Z","shell.execute_reply.started":"2026-01-29T11:03:58.161433Z","shell.execute_reply":"2026-01-29T11:03:58.187623Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[df['Year'].isna()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:03:58.190059Z","iopub.execute_input":"2026-01-29T11:03:58.190336Z","iopub.status.idle":"2026-01-29T11:03:58.21614Z","shell.execute_reply.started":"2026-01-29T11:03:58.190312Z","shell.execute_reply":"2026-01-29T11:03:58.215226Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We see year is missing where the condition is New, so let's change year to 2025(when the dataset was scraped) where the Condition is new, and then remove the remaining rows\n\nWhile we are at it, let's change columns type to int64","metadata":{}},{"cell_type":"code","source":"df['Year'] = df['Year'].astype('Int64')\n\nfilter_year = (df['Year'].isna()) & (df['Condition'] == 'New')\ndf.loc[filter_year, 'Year'] = 2025\n\nprint(f\"Updated {filter_year.sum()} rows\")\nprint(f\"Removed {df['Year'].isna().sum() } rows \")\ndf.dropna(subset=['Year'], inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:03:58.219141Z","iopub.execute_input":"2026-01-29T11:03:58.219471Z","iopub.status.idle":"2026-01-29T11:03:58.251481Z","shell.execute_reply.started":"2026-01-29T11:03:58.219443Z","shell.execute_reply":"2026-01-29T11:03:58.25047Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's look at country","metadata":{}},{"cell_type":"code","source":"df[df['Country'].isna()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:03:58.252419Z","iopub.execute_input":"2026-01-29T11:03:58.252672Z","iopub.status.idle":"2026-01-29T11:03:58.282867Z","shell.execute_reply.started":"2026-01-29T11:03:58.25265Z","shell.execute_reply":"2026-01-29T11:03:58.282045Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"To keep those rows, I'll set Country to unknown in the rows it's missing","metadata":{}},{"cell_type":"code","source":"df['Country'] = df['Country'].fillna('Unknown')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:03:58.284049Z","iopub.execute_input":"2026-01-29T11:03:58.284583Z","iopub.status.idle":"2026-01-29T11:03:58.295929Z","shell.execute_reply.started":"2026-01-29T11:03:58.284549Z","shell.execute_reply":"2026-01-29T11:03:58.295Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's look at drivetrain now","metadata":{}},{"cell_type":"code","source":"df[df['Drivetrain'].isna()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:03:58.297192Z","iopub.execute_input":"2026-01-29T11:03:58.297523Z","iopub.status.idle":"2026-01-29T11:03:58.333258Z","shell.execute_reply.started":"2026-01-29T11:03:58.297495Z","shell.execute_reply":"2026-01-29T11:03:58.332411Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's update the rows where we find a match between make and model having the info about drivetrain,\nand set to unknown the remaining rows","metadata":{}},{"cell_type":"code","source":"# grouping by make, model getting the mode of drivetrain by pair and then applying it to na values\n# to corresponding pairs\ndrivetrain_by_make_model = df.groupby(['Make', 'Model'])['Drivetrain'].transform(lambda x: x.mode()[0] \n                                                                   if not x.mode().empty else None)\ndf['Drivetrain'] = df['Drivetrain'].fillna(drivetrain_by_make_model)\n\nprint(f\"{df['Drivetrain'].isna().sum()} rows left with unknown drivetrain\")\n\ndf['Drivetrain'] = df['Drivetrain'].fillna(\"Unknown\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:03:58.334321Z","iopub.execute_input":"2026-01-29T11:03:58.33468Z","iopub.status.idle":"2026-01-29T11:03:58.719508Z","shell.execute_reply.started":"2026-01-29T11:03:58.334649Z","shell.execute_reply":"2026-01-29T11:03:58.718667Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now let's apply the same approach to the remaining columns and check where we are at.","metadata":{}},{"cell_type":"code","source":"engine_by_make_model = df.groupby(['Make', 'Model'])['Engine_Size_cc'].transform('median')\ndf['Engine_Size_cc'] = df['Engine_Size_cc'].fillna(engine_by_make_model)\n\nfor col in ['Cylinders', 'Seats', 'Doors']:\n    col_by_make_model = df.groupby(['Make', 'Model'])[col].transform(\n        lambda x: x.mode()[0] \n        if not x.mode().empty else None\n    )\n    df[col] = df[col].fillna(col_by_make_model)\n\ndf['Color'] = df['Color'].fillna('Unknown')\ndf['Upholstery'] = df['Upholstery'].fillna('Unknown')\n\ndf.info()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:03:58.720579Z","iopub.execute_input":"2026-01-29T11:03:58.720901Z","iopub.status.idle":"2026-01-29T11:03:59.627661Z","shell.execute_reply.started":"2026-01-29T11:03:58.720866Z","shell.execute_reply":"2026-01-29T11:03:59.626691Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's remove the few hundred rows that still have missing values, change the type of columns\nwhere it's not what it's supposed to be, and we should be good.","metadata":{}},{"cell_type":"code","source":"df.dropna(inplace=True)\n\ndf['Year'] = df['Year'].astype('int64')\ndf['Engine_Size_cc'] = df['Engine_Size_cc'].astype('int64')\ndf['Cylinders'] = df['Cylinders'].astype('int64')\ndf['Seats'] = df['Seats'].astype('int64')\ndf['Doors'] = df['Doors'].astype('int64')\n\ndf.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:03:59.628744Z","iopub.execute_input":"2026-01-29T11:03:59.62908Z","iopub.status.idle":"2026-01-29T11:03:59.710187Z","shell.execute_reply.started":"2026-01-29T11:03:59.62905Z","shell.execute_reply":"2026-01-29T11:03:59.709243Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Perfect, we only removed about 5% of rows but still kept our dataframe with meaningful data.\nLastly let's fix the outliers by looking at min and max values we got.","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:03:59.711314Z","iopub.execute_input":"2026-01-29T11:03:59.711725Z","iopub.status.idle":"2026-01-29T11:03:59.750241Z","shell.execute_reply.started":"2026-01-29T11:03:59.711699Z","shell.execute_reply":"2026-01-29T11:03:59.749449Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"To remove the outliers, we need to know that the low values for enginesize and cylinders are due to the fact we have electric cars in the dataset.","metadata":{}},{"cell_type":"code","source":"df = df[(df['Price'] >= 500) & (df['Price'] < 9000000)]\ndf = df[df['Mileage_km'] < 1000000]\ndf = df[df['Engine_Size_cc'] < 8000]\ndf = df[df['Power_hp'] > 10]\ndf = df[(df['Seats'] > 1 )& (df['Seats'] < 10)]\ndf = df[(df['Doors'] > 1 )& (df['Doors'] < 7)]\n\nprint(f\"Data cleaned! Remaining rows: {len(df)}\")\ndf.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:03:59.751471Z","iopub.execute_input":"2026-01-29T11:03:59.75184Z","iopub.status.idle":"2026-01-29T11:03:59.853604Z","shell.execute_reply.started":"2026-01-29T11:03:59.751814Z","shell.execute_reply":"2026-01-29T11:03:59.852645Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.to_csv(\"df_clean.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:03:59.854843Z","iopub.execute_input":"2026-01-29T11:03:59.855196Z","iopub.status.idle":"2026-01-29T11:04:00.325266Z","shell.execute_reply.started":"2026-01-29T11:03:59.855161Z","shell.execute_reply":"2026-01-29T11:04:00.324301Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Data Exploration","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"ticks\")\nsns.set_palette(\"muted\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:00.326591Z","iopub.execute_input":"2026-01-29T11:04:00.326888Z","iopub.status.idle":"2026-01-29T11:04:01.457768Z","shell.execute_reply.started":"2026-01-29T11:04:00.326862Z","shell.execute_reply":"2026-01-29T11:04:01.456856Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.1 Price Analysis","metadata":{}},{"cell_type":"markdown","source":"Let's start by looking at price distribution","metadata":{}},{"cell_type":"code","source":"sns.displot(df, x=\"Price\", kde=True, log_scale=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:01.458831Z","iopub.execute_input":"2026-01-29T11:04:01.45921Z","iopub.status.idle":"2026-01-29T11:04:02.746253Z","shell.execute_reply.started":"2026-01-29T11:04:01.459184Z","shell.execute_reply":"2026-01-29T11:04:02.745475Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We see the data is right skewed, with most of cars ranging from 10k to 30k, which is pretty normal for the car market.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.boxplot(data=df, x=\"Body\", y =\"Price\", log_scale=True,hue =\"Body\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:02.74727Z","iopub.execute_input":"2026-01-29T11:04:02.747552Z","iopub.status.idle":"2026-01-29T11:04:03.36347Z","shell.execute_reply.started":"2026-01-29T11:04:02.747514Z","shell.execute_reply":"2026-01-29T11:04:03.362412Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's give a look to which are the most expensive cars and which are the cheapest","metadata":{}},{"cell_type":"code","source":"df['Make_Model'] = df['Make'] + \" \" + df['Model']\n\ntop_10_expensive_cars = df.nlargest(10, 'Price')\nbottom_10_cheap_cars = df.nsmallest(10, 'Price')\n\nfig, axes = plt.subplots(2, 1, figsize=(10, 12))\n\n\naxes[0].barh(range(10), top_10_expensive_cars['Price'], color='salmon')\naxes[0].set_yticks(range(10))\naxes[0].set_yticklabels(top_10_expensive_cars['Make_Model'])\naxes[0].invert_yaxis() \naxes[0].set_title(\"Top 10 Most Expensive Listings\")\naxes[0].set_xlabel(\"Price (M€)\", fontsize=12)\naxes[0].set_ylabel(\"Car Model\", fontsize=12)\n\naxes[1].barh(range(10), bottom_10_cheap_cars['Price'], color='seagreen')\naxes[1].set_yticks(range(10))\naxes[1].set_yticklabels(bottom_10_cheap_cars['Make_Model'])\naxes[1].invert_yaxis() \naxes[1].set_title(\"Top 10 Cheapest Listings\")\naxes[1].set_xlabel(\"Price (€)\", fontsize=12)\naxes[1].set_ylabel(\"Car Model\", fontsize=12)\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:03.364715Z","iopub.execute_input":"2026-01-29T11:04:03.365075Z","iopub.status.idle":"2026-01-29T11:04:03.790721Z","shell.execute_reply.started":"2026-01-29T11:04:03.365037Z","shell.execute_reply":"2026-01-29T11:04:03.789538Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can see how ferrari dominates the charts for the expensive cars, while in the cheap we find Lancia,Chevrolet and Honda.\n","metadata":{}},{"cell_type":"markdown","source":"## 2.2 Depreciation Factor (Age and Mileage) Analysis","metadata":{}},{"cell_type":"markdown","source":"First, let's create categories of budget, mid-range, premium and luxury cars, to look how price is affected in each category.\n\n* Budget : Price < 12k€\n* Mid-Tier : 12k€ <= Price < 25k€ \n* Premium : 25k€ <= Price <  60k€ \n* Luxury : Price >= 60k€\n","metadata":{}},{"cell_type":"code","source":"def get_category(price):\n    if price < 12000:\n        return 'Budget'\n    elif price < 25000:\n        return 'Mid-Range'\n    elif price < 55000:\n        return 'Premium'\n    else:\n        return 'Luxury'\n\ndf['Category'] = df['Price'].apply(get_category)\n\nprint(df['Category'].value_counts().sort_index())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:03.79198Z","iopub.execute_input":"2026-01-29T11:04:03.792441Z","iopub.status.idle":"2026-01-29T11:04:03.814592Z","shell.execute_reply.started":"2026-01-29T11:04:03.792303Z","shell.execute_reply":"2026-01-29T11:04:03.813502Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntemp_df = df.copy()\ntemp_df['Mileage_Bracket'] = pd.cut(temp_df['Mileage_km'], \n                                     bins=[0, 25000, 50000, 75000, 100000, 150000, 200000, 300000],\n                                     labels=['0-25k', '25-50k', '50-75k', '75-100k', '100-150k', '150-200k', '200k+'])\n\n# Calculate average price \nprice_by_mileage = temp_df.groupby(['Category', 'Mileage_Bracket'], observed=True)['Price'].mean().reset_index()\n\n\nplt.figure(figsize=(14, 8))\nfor category in ['Budget', 'Mid-Range', 'Premium', 'Luxury']:\n    data = price_by_mileage[price_by_mileage['Category'] == category].copy()\n    baseline_price = data['Price'].iloc[0]  # First mileage bracket (0-25k)\n    data['Pct_Loss'] = ((baseline_price - data['Price']) / baseline_price) * 100\n    \n    plt.plot(data['Mileage_Bracket'], data['Pct_Loss'], \n             marker='o', linewidth=2.5, markersize=8, label=category)\n\nplt.xlabel('Mileage Bracket', fontsize=12)\nplt.ylabel('Price Loss (%)', fontsize=12)\nplt.title('Percentage Price Loss by Mileage Across Categories', fontsize=14, fontweight='bold')\nplt.legend(title='Price Category', fontsize=11)\nplt.xticks(rotation=45)\nplt.grid(True, alpha=0.3)\nplt.axhline(y=0, color='black', linestyle='--', linewidth=1)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:03.815524Z","iopub.execute_input":"2026-01-29T11:04:03.815798Z","iopub.status.idle":"2026-01-29T11:04:04.170992Z","shell.execute_reply.started":"2026-01-29T11:04:03.815764Z","shell.execute_reply":"2026-01-29T11:04:04.169884Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now to look at age let's create another column of car age doing 2026-year","metadata":{}},{"cell_type":"code","source":"df['Age'] = 2026 - df['Year']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:04.172341Z","iopub.execute_input":"2026-01-29T11:04:04.172679Z","iopub.status.idle":"2026-01-29T11:04:04.178972Z","shell.execute_reply.started":"2026-01-29T11:04:04.172651Z","shell.execute_reply":"2026-01-29T11:04:04.177885Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"temp_df = df.copy()\ntemp_df['Age_Brackets'] = pd.cut(temp_df['Age'], \n                                 bins=[0, 1, 2, 3, 4, 5, 6, 7, 8, 100],  # Fixed: proper bin edges\n                                 labels=['1', '2', '3', '4', '5', '6', '7', '8', '9+'])\n\n# Calculate average price \nprice_by_age = temp_df.groupby(['Category', 'Age_Brackets'], observed=True)['Price'].mean().reset_index()\n\nplt.figure(figsize=(14, 8))\nfor category in ['Budget', 'Mid-Range', 'Premium', 'Luxury']:\n    data = price_by_age[price_by_age['Category'] == category].copy()\n    baseline_price = data['Price'].iloc[0]  # First age bracket\n    data['Pct_Loss'] = ((baseline_price - data['Price']) / baseline_price) * 100\n    \n    plt.plot(data['Age_Brackets'], data['Pct_Loss'],  \n             marker='o', linewidth=2.5, markersize=8, label=category)\n\nplt.xlabel('Car Age (years)', fontsize=12)\nplt.ylabel('Price Loss (%)', fontsize=12)\nplt.title('Percentage Price Loss by Car Age Across Categories', fontsize=14, fontweight='bold')  # Fixed: changed title\nplt.legend(title='Price Category', fontsize=11)\nplt.grid(True, alpha=0.3)\nplt.axhline(y=0, color='black', linestyle='--', linewidth=1)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:04.180298Z","iopub.execute_input":"2026-01-29T11:04:04.180779Z","iopub.status.idle":"2026-01-29T11:04:04.51146Z","shell.execute_reply.started":"2026-01-29T11:04:04.180746Z","shell.execute_reply":"2026-01-29T11:04:04.510463Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In those two graphs we can see how mileage has a big impact on all categories, while age affects the middle and luxury range the most.","metadata":{}},{"cell_type":"markdown","source":"Finally let's look and see if power correlates linearly to price.","metadata":{}},{"cell_type":"code","source":"sns.jointplot(data=df, x='Power_hp', y='Price', kind='reg',line_kws={'color':'red'}, height=10)\nplt.xlabel(\"Power\")\nplt.ylabel(\"Price (€)\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:04.51571Z","iopub.execute_input":"2026-01-29T11:04:04.516027Z","iopub.status.idle":"2026-01-29T11:04:13.795174Z","shell.execute_reply.started":"2026-01-29T11:04:04.515998Z","shell.execute_reply":"2026-01-29T11:04:13.794309Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"From this graph we can see that power correlates well with cars under 100k, but we got some outliers of cars with high price value but not so much in power.","metadata":{}},{"cell_type":"markdown","source":"## 2.3 Features Analysis ","metadata":{}},{"cell_type":"markdown","source":"Let's now look at some pie plots of categorical values and how they are distributed","metadata":{}},{"cell_type":"code","source":"columns_to_plot = ['Full_Service_History', 'Fuel_Type', 'Body', 'Non_Smoker_Vehicle', \n                   'Gearbox', 'Drivetrain']\n\nfig, axes = plt.subplots(2, 3, figsize=(20, 10))\naxes = axes.flatten()\n\nfor i, col in enumerate(columns_to_plot):\n    data = df[col].value_counts()\n    percentages = (data / data.sum()) * 100\n    data_filtered = data[percentages > 2]\n    \n    other_count = data[percentages <= 2].sum()\n    other_percentage = (other_count / data.sum()) * 100\n    if other_count > 0 and other_percentage >= 0.5:\n        data_filtered['Other'] = other_count\n    \n    # Pie chart WITHOUT labels, only percentages\n    wedges, texts, autotexts = axes[i].pie(data_filtered.values, \n                                            autopct='%1.1f%%', startangle=90, \n                                            colors=sns.color_palette('Set2', len(data_filtered)))\n    \n    # Add legend with BIGGER font\n    axes[i].legend(data_filtered.index, loc='center left', bbox_to_anchor=(1, 0, 0.5, 1), \n                   fontsize=12)  # Changed from 8 to 10\n    axes[i].set_title(f'{col} Distribution', fontsize=15, fontweight='bold')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:13.796523Z","iopub.execute_input":"2026-01-29T11:04:13.796883Z","iopub.status.idle":"2026-01-29T11:04:14.479987Z","shell.execute_reply.started":"2026-01-29T11:04:13.796844Z","shell.execute_reply":"2026-01-29T11:04:14.478918Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"From this graph we can see that there are more automatic cars than manual, front wheel drive and gasoline and, strangely, the most common type is off-road (SUV's).","metadata":{}},{"cell_type":"markdown","source":"# 3. Price Prediction","metadata":{}},{"cell_type":"code","source":"import scipy.stats\n\ndf = df.drop(['Image_url', 'Seller','Year', 'Make_Model', 'Category'], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:14.481133Z","iopub.execute_input":"2026-01-29T11:04:14.481485Z","iopub.status.idle":"2026-01-29T11:04:14.495709Z","shell.execute_reply.started":"2026-01-29T11:04:14.481449Z","shell.execute_reply":"2026-01-29T11:04:14.494571Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.1 Feature Engineering ","metadata":{}},{"cell_type":"markdown","source":"Let's add some columns.","metadata":{}},{"cell_type":"code","source":"df['Mileage_Per_Year'] = (df['Mileage_km'] / df['Age']).replace([np.inf, -np.inf], 0).fillna(0)\ndf['Mileage_Per_Year'] = df['Mileage_Per_Year'].astype('int64')\ndf['Is_Automatic'] = (df['Gearbox'].str.contains('Automatic|Semi-automatic', case=False, na=False)).astype(int)\ndf['Premium_Features'] = df['Full_Service_History'].astype(int) + df['Non_Smoker_Vehicle'].astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:14.49688Z","iopub.execute_input":"2026-01-29T11:04:14.497145Z","iopub.status.idle":"2026-01-29T11:04:14.531016Z","shell.execute_reply.started":"2026-01-29T11:04:14.497118Z","shell.execute_reply":"2026-01-29T11:04:14.529615Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numeric_df = df.select_dtypes(include='number')\n\ndf_corr = numeric_df.corr().round(2)\n\nplt.figure(figsize=(16,6))\nsns.heatmap(df_corr, annot=True, cmap='coolwarm', fmt='0.2f', linewidths = 0.5 , \n            annot_kws={'size': 16})\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:14.531935Z","iopub.execute_input":"2026-01-29T11:04:14.532191Z","iopub.status.idle":"2026-01-29T11:04:15.021992Z","shell.execute_reply.started":"2026-01-29T11:04:14.532168Z","shell.execute_reply":"2026-01-29T11:04:15.020464Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now let's make logarithmic all the values that are right skewed.","metadata":{}},{"cell_type":"code","source":"numerical_cols = [cname for cname in df.columns if df[cname].dtypes == 'int64' and cname != 'Price']\n\nskew_df = pd.DataFrame(numerical_cols, columns =['Feature'])\n\nskew_df['Skew'] = skew_df['Feature'].apply(lambda feature: scipy.stats.skew(df[feature]))\n\nskew_df['Absolute Skew'] = skew_df['Skew'].apply(abs)\n\nskew_df['Skewed'] = skew_df['Absolute Skew'].apply(lambda x: True if x >= 0.6 else False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:15.024083Z","iopub.execute_input":"2026-01-29T11:04:15.024503Z","iopub.status.idle":"2026-01-29T11:04:15.048833Z","shell.execute_reply.started":"2026-01-29T11:04:15.024464Z","shell.execute_reply":"2026-01-29T11:04:15.047836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"skew_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:15.050101Z","iopub.execute_input":"2026-01-29T11:04:15.050486Z","iopub.status.idle":"2026-01-29T11:04:15.061832Z","shell.execute_reply.started":"2026-01-29T11:04:15.050454Z","shell.execute_reply":"2026-01-29T11:04:15.060938Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for column in skew_df.query('Skewed == True')['Feature'].values:\n    df[column] = np.log1p(df[column])\n\ndf['Price'] = np.log1p(df['Price'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:15.063536Z","iopub.execute_input":"2026-01-29T11:04:15.063863Z","iopub.status.idle":"2026-01-29T11:04:15.096499Z","shell.execute_reply.started":"2026-01-29T11:04:15.063834Z","shell.execute_reply":"2026-01-29T11:04:15.095483Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Not encoding model because i would have more than 1000 columns and risk that everything crashes","metadata":{}},{"cell_type":"code","source":"df['Full_Service_History'] = df['Full_Service_History'].astype(int)\ndf['Non_Smoker_Vehicle'] = df['Non_Smoker_Vehicle'].astype(int)\n\ncategorical = ['Make', 'Body', 'Country', 'Condition', \n               'Fuel_Type', 'Drivetrain', 'Upholstery','Color']\n\ndf = df.drop(columns=(\"Gearbox\"))\n\ndf_encoded = pd.get_dummies(df, columns=categorical, drop_first=True,dtype = int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:15.097626Z","iopub.execute_input":"2026-01-29T11:04:15.097953Z","iopub.status.idle":"2026-01-29T11:04:15.202447Z","shell.execute_reply.started":"2026-01-29T11:04:15.097922Z","shell.execute_reply":"2026-01-29T11:04:15.201466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_encoded = df_encoded.drop(columns =(\"Model\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:15.203622Z","iopub.execute_input":"2026-01-29T11:04:15.203944Z","iopub.status.idle":"2026-01-29T11:04:15.22687Z","shell.execute_reply.started":"2026-01-29T11:04:15.203917Z","shell.execute_reply":"2026-01-29T11:04:15.225747Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.2 Linear Regression ","metadata":{}},{"cell_type":"markdown","source":"Now that we have our encoded dataset, we can start with using linear regression and see what results we get, and later use different models to see what performs better.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:15.228197Z","iopub.execute_input":"2026-01-29T11:04:15.228614Z","iopub.status.idle":"2026-01-29T11:04:15.57813Z","shell.execute_reply.started":"2026-01-29T11:04:15.228571Z","shell.execute_reply":"2026-01-29T11:04:15.57712Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Splitting test and train data","metadata":{}},{"cell_type":"code","source":"df_encoded.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:15.579192Z","iopub.execute_input":"2026-01-29T11:04:15.579778Z","iopub.status.idle":"2026-01-29T11:04:15.621663Z","shell.execute_reply.started":"2026-01-29T11:04:15.579749Z","shell.execute_reply":"2026-01-29T11:04:15.620746Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = df_encoded.drop('Price', axis=1)\ny = df_encoded['Price']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:15.622668Z","iopub.execute_input":"2026-01-29T11:04:15.622927Z","iopub.status.idle":"2026-01-29T11:04:15.694249Z","shell.execute_reply.started":"2026-01-29T11:04:15.622897Z","shell.execute_reply":"2026-01-29T11:04:15.693322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reg = LinearRegression()\nreg.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:15.695605Z","iopub.execute_input":"2026-01-29T11:04:15.695986Z","iopub.status.idle":"2026-01-29T11:04:15.903904Z","shell.execute_reply.started":"2026-01-29T11:04:15.695958Z","shell.execute_reply":"2026-01-29T11:04:15.902805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = reg.predict(X_test)\n\nsns.scatterplot(x = pred, y = y_test)\nplt.title(\"Linear Regression\")\nplt.xlabel(\"Predictions\")\nplt.ylabel(\"Evaluation of our model\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:15.90475Z","iopub.execute_input":"2026-01-29T11:04:15.905025Z","iopub.status.idle":"2026-01-29T11:04:16.123441Z","shell.execute_reply.started":"2026-01-29T11:04:15.904999Z","shell.execute_reply":"2026-01-29T11:04:16.122325Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Metrics in LOG scale (what the model actually optimizes)\nscores_log = {\n    \"R2\": r2_score(y_test, pred),\n    \"MAE\": mean_absolute_error(y_test, pred),\n    \"RMSE\": np.sqrt(mean_squared_error(y_test, pred))\n}\nprint(\"Metrics in LOG scale:\")\nprint(pd.DataFrame(scores_log, index=[\"Test\"]))\n\n# Metrics in ORIGINAL scale (what users care about)\ny_test_original = np.exp(y_test)\npred_original = np.exp(pred)\n\nscores_original = {\n    \"R2\": r2_score(y_test_original, pred_original),\n    \"MAE\": mean_absolute_error(y_test_original, pred_original),\n    \"RMSE\": np.sqrt(mean_squared_error(y_test_original, pred_original))\n}\nprint(\"\\nMetrics in ORIGINAL scale (€):\")\nprint(pd.DataFrame(scores_original, index=[\"Test\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:16.12485Z","iopub.execute_input":"2026-01-29T11:04:16.125188Z","iopub.status.idle":"2026-01-29T11:04:16.145341Z","shell.execute_reply.started":"2026-01-29T11:04:16.12516Z","shell.execute_reply":"2026-01-29T11:04:16.144427Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As we can see we have some bad results, so let's see how many outliers are in our dataset and \nremove the ones where we have only few data about.","metadata":{}},{"cell_type":"code","source":"price_original = np.exp(df_encoded['Price'])\n\nprint(f\"Cars < 1000€: {(price_original < 1000).sum()}\")\nprint(f\"Cars < 3000€: {(price_original < 3000).sum()}\")\nprint(f\"Cars > 200k€: {(price_original > 200000).sum()}\")\nprint(f\"Cars > 500k€: {(price_original > 500000).sum()}\")\nprint(f\"Cars > 1M€: {(price_original > 1000000).sum()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:16.147749Z","iopub.execute_input":"2026-01-29T11:04:16.148069Z","iopub.status.idle":"2026-01-29T11:04:16.158856Z","shell.execute_reply.started":"2026-01-29T11:04:16.148041Z","shell.execute_reply":"2026-01-29T11:04:16.157974Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"let's remove the cars with price >500k and price < 3k and try again","metadata":{}},{"cell_type":"code","source":"df_encoded['Price'] = np.exp(df_encoded['Price'])\ndf_encoded = df_encoded[(df_encoded['Price'] > 3000) & (df_encoded['Price'] < 500000)]\n\ndf_encoded['Price'] = np.log1p(df_encoded['Price'])\n\nX = df_encoded.drop('Price', axis=1)\ny = df_encoded['Price']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nreg = LinearRegression()\nreg.fit(X_train, y_train)\npred = reg.predict(X_test)\n\n\nscores_log = {\n    \"R2\": r2_score(y_test, pred),\n    \"MAE\": mean_absolute_error(y_test, pred),\n    \"RMSE\": np.sqrt(mean_squared_error(y_test, pred))\n}\nprint(\"Metrics in LOG scale:\")\nprint(pd.DataFrame(scores_log, index=[\"Test\"]))\n\n\ny_test_original = np.exp(y_test)\npred_original = np.exp(pred)\n\nscores_original = {\n    \"R2\": r2_score(y_test_original, pred_original),\n    \"MAE\": mean_absolute_error(y_test_original, pred_original),\n    \"RMSE\": np.sqrt(mean_squared_error(y_test_original, pred_original))\n}\nprint(\"\\nMetrics in ORIGINAL scale (€):\")\nprint(pd.DataFrame(scores_original, index=[\"Test\"]))\n\nlinear_r2 = scores_original['R2']\nlinear_mae = scores_original['MAE']\nlinear_rmse = scores_original['RMSE']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:16.160005Z","iopub.execute_input":"2026-01-29T11:04:16.160411Z","iopub.status.idle":"2026-01-29T11:04:16.418167Z","shell.execute_reply.started":"2026-01-29T11:04:16.160355Z","shell.execute_reply":"2026-01-29T11:04:16.417366Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We get better results, but we can do more.","metadata":{}},{"cell_type":"markdown","source":"## 3.3 Forest Regressor","metadata":{}},{"cell_type":"markdown","source":"Since cars prices aren't dictated by linear correlations in most cases, we can use a random forest regressor which uses an ensemble of decision trees that can capture non-linear relationships and complex interactions between features.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nforest = RandomForestRegressor()\n\nforest.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:04:16.419592Z","iopub.execute_input":"2026-01-29T11:04:16.419926Z","iopub.status.idle":"2026-01-29T11:05:02.39178Z","shell.execute_reply.started":"2026-01-29T11:04:16.419896Z","shell.execute_reply":"2026-01-29T11:05:02.390619Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred_log = forest.predict(X_test)\n\n\ny_test_real = np.exp(y_test)\ny_pred_real = np.exp(y_pred_log)\n\nforest_r2 = r2_score(y_test_real, y_pred_real)\nforest_mae = mean_absolute_error(y_test_real, y_pred_real)\nforest_rmse = np.sqrt(mean_squared_error(y_test_real, y_pred_real))\n\nprint(f\"--- Random Forest Performance ---\")\nprint(f\"R2 Score: {forest_r2:.4f}\")\nprint(f\"MAE (Euro): €{forest_mae:,.2f}\")\nprint(f\"RMSE (Euro): €{forest_rmse:,.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:05:02.392996Z","iopub.execute_input":"2026-01-29T11:05:02.393647Z","iopub.status.idle":"2026-01-29T11:05:02.76236Z","shell.execute_reply.started":"2026-01-29T11:05:02.393618Z","shell.execute_reply":"2026-01-29T11:05:02.761477Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's look at which are considered the most important values to predict price","metadata":{}},{"cell_type":"code","source":"feat_importances = pd.Series(forest.feature_importances_, index=forest.feature_names_in_)\ntop_30 = feat_importances.nlargest(30)\n\nplt.figure(figsize=(10, 8))\nsns.barplot(x=top_30.values, y=top_30.index, palette='viridis')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:05:02.763958Z","iopub.execute_input":"2026-01-29T11:05:02.764257Z","iopub.status.idle":"2026-01-29T11:05:03.301733Z","shell.execute_reply.started":"2026-01-29T11:05:02.764229Z","shell.execute_reply":"2026-01-29T11:05:03.300509Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"From this barplot we can see how power and age are the most important features, together with km, as we expected from our data exploration.","metadata":{}},{"cell_type":"markdown","source":"## 3.4 CatBoost","metadata":{}},{"cell_type":"markdown","source":"For our last regressor, let's use CatBoost, it uses decision trees but the way it differs from a random forest is that for every tree it corrects the errors made by the previous trees.\nIt also handles categorical values natively, so we can now include cars' model in our regressor.","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostRegressor\n\ncategorical = ['Make', 'Model', 'Body', 'Country', 'Condition', 'Fuel_Type', 'Drivetrain',\n              'Color', 'Upholstery']\n\n# Using 3k-500k range\ndf['Price'] = np.exp(df['Price'])\ndf = df[(df['Price'] > 3000) & (df['Price'] < 500000)]\ndf['Price'] = np.log1p(df['Price'])\n\n\nX = df.drop('Price', axis=1)\ny = df['Price']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\ncat = CatBoostRegressor(learning_rate=0.03, iterations=2000,depth=7,\n                        cat_features=categorical,loss_function='RMSE',verbose=200,\n                        random_seed=42)\n\ncat.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:05:03.303138Z","iopub.execute_input":"2026-01-29T11:05:03.303517Z","iopub.status.idle":"2026-01-29T11:06:19.212865Z","shell.execute_reply.started":"2026-01-29T11:05:03.303488Z","shell.execute_reply":"2026-01-29T11:06:19.21195Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = cat.predict(X_test)\ny_pred_original = np.exp(y_pred)\ny_test_original = np.exp(y_test)\n\ncat_r2 = r2_score(y_test_original, y_pred_original)\ncat_mae = mean_absolute_error(y_test_original, y_pred_original)\ncat_rmse = np.sqrt(mean_squared_error(y_test_original, y_pred_original))\n\nprint(f\"--- Catboost Performance ---\")\nprint(f\"R2 Score: {cat_r2:.4f}\")\nprint(f\"MAE (Euro): €{cat_mae:,.2f}\")\nprint(f\"RMSE (Euro): €{cat_rmse:,.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:06:19.214136Z","iopub.execute_input":"2026-01-29T11:06:19.214536Z","iopub.status.idle":"2026-01-29T11:06:19.320635Z","shell.execute_reply.started":"2026-01-29T11:06:19.214497Z","shell.execute_reply":"2026-01-29T11:06:19.319486Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.5 Final Results","metadata":{}},{"cell_type":"code","source":"data = {\n    'Linear Regression': {\n        'R2 Score': linear_r2,\n        'MAE (€)': linear_mae,\n        'RMSE (€)': linear_rmse\n    },\n    'Random Forest': {\n        'R2 Score': forest_r2,\n        'MAE (€)': forest_mae,\n        'RMSE (€)': forest_rmse\n    },\n    'CatBoost': {\n        'R2 Score': cat_r2,\n        'MAE (€)': cat_mae,\n        'RMSE (€)': cat_rmse\n    }\n}\n\npd.DataFrame(data).T.style.format({\n    'R2 Score': '{:.4f}',\n    'MAE (€)': '€{:,.2f}',\n    'RMSE (€)': '€{:,.2f}'\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T11:07:14.553622Z","iopub.execute_input":"2026-01-29T11:07:14.553981Z","iopub.status.idle":"2026-01-29T11:07:14.670432Z","shell.execute_reply.started":"2026-01-29T11:07:14.553953Z","shell.execute_reply":"2026-01-29T11:07:14.669528Z"}},"outputs":[],"execution_count":null}]}